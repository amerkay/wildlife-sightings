{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce468168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pygbif python-dwca-reader\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from pygbif import occurrences\n",
    "\n",
    "# GBIF credentials\n",
    "GBIF_USER = \"wildamer\"\n",
    "GBIF_PASS = \"8#yGm%S7Y!LjYPSL\"\n",
    "GBIF_EMAIL = \"itsme@wildamer.com\"\n",
    "\n",
    "# Taxon key for Barn Owl (Tyto alba)\n",
    "TAXON_KEY = 2497921\n",
    "\n",
    "# Date range for occurrences\n",
    "DATE_START = \"2010-01-01\"\n",
    "DATE_END   = \"2025-12-31\"\n",
    "\n",
    "# European countries (ISO 2-letter codes)\n",
    "# european_countries = [\n",
    "#     \"AD\", \"AL\", \"AT\", \"BA\", \"BE\", \"BG\", \"BY\", \"CH\", \"CY\", \"CZ\", \n",
    "#     \"DE\", \"DK\", \"EE\", \"ES\", \"FI\", \"FR\", \"GB\", \"GR\", \"HR\", \"HU\", \n",
    "#     \"IE\", \"IS\", \"IT\", \"LI\", \"LT\", \"LU\", \"LV\", \"MC\", \"MD\", \"ME\", \n",
    "#     \"MK\", \"MT\", \"NL\", \"NO\", \"PL\", \"PT\", \"RO\", \"RS\", \"SE\", \"SI\", \n",
    "#     \"SK\", \"SM\", \"UA\", \"VA\"\n",
    "# ]\n",
    "european_countries = [ \"GB\", \"IE\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de54fd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for 2 European countries\n",
      "Countries: GB, IE\n",
      "Predicate structure: 5 main predicates with 2 country options\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Your download key is 0012178-250802193616735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download initiated (key=0012178-250802193616735)\n",
      "Current status: PREPARING\n",
      "Current status: PREPARING\n",
      "Current status: PREPARING\n",
      "Current status: RUNNING\n",
      "Current status: RUNNING\n",
      "Current status: RUNNING\n",
      "Current status: SUCCEEDED\n",
      "Downloading archive from https://api.gbif.org/v1/occurrence/download/request/0012178-250802193616735.zip …\n",
      "Extracted to 0012178-250802193616735\n"
     ]
    }
   ],
   "source": [
    "# Build country predicates as individual dictionaries\n",
    "country_predicates = [{\"type\": \"equals\", \"key\": \"COUNTRY\", \"value\": country} for country in european_countries]\n",
    "\n",
    "# Build the main predicate structure\n",
    "predicate = {\n",
    "    \"type\": \"and\",\n",
    "    \"predicates\": [\n",
    "        {\"type\": \"equals\", \"key\": \"TAXON_KEY\", \"value\": str(TAXON_KEY)},\n",
    "        {\"type\": \"greaterThanOrEquals\", \"key\": \"EVENT_DATE\", \"value\": DATE_START},\n",
    "        {\"type\": \"lessThanOrEquals\", \"key\": \"EVENT_DATE\", \"value\": DATE_END},\n",
    "        {\"type\": \"equals\", \"key\": \"HAS_COORDINATE\", \"value\": \"true\"},\n",
    "        {\n",
    "            \"type\": \"or\",\n",
    "            \"predicates\": country_predicates\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"Downloading data for {len(european_countries)} European countries\")\n",
    "print(f\"Countries: {', '.join(european_countries)}\")\n",
    "print(f\"Predicate structure: {len(predicate['predicates'])} main predicates with {len(country_predicates)} country options\")\n",
    "\n",
    "# 1. Initiate the asynchronous download request\n",
    "res = occurrences.download(\n",
    "    queries=predicate,\n",
    "    format=\"SIMPLE_CSV\",\n",
    "    user=GBIF_USER,\n",
    "    pwd=GBIF_PASS,\n",
    "    email=GBIF_EMAIL\n",
    ")\n",
    "download_key = res[0]\n",
    "print(f\"Download initiated (key={download_key})\")\n",
    "\n",
    "# 2. Poll the download status until it succeeds\n",
    "while True:\n",
    "    meta = occurrences.download_meta(download_key)\n",
    "    status = meta[\"status\"]\n",
    "    print(f\"Current status: {status}\")\n",
    "    if status == \"SUCCEEDED\":\n",
    "        break\n",
    "    if status in (\"KILLED\", \"FAILED\"):\n",
    "        raise RuntimeError(f\"GBIF download {download_key} failed: {status}\")\n",
    "    time.sleep(30)\n",
    "\n",
    "# 3. Fetch the completed ZIP archive\n",
    "download_url = meta[\"downloadLink\"]\n",
    "zip_path = f\"{download_key}.zip\"\n",
    "print(f\"Downloading archive from {download_url} …\")\n",
    "r = requests.get(download_url)\n",
    "r.raise_for_status()\n",
    "with open(zip_path, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "# 4. Unzip into a directory named after the download key\n",
    "extract_dir = download_key\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    z.extractall(extract_dir)\n",
    "print(f\"Extracted to {extract_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c27a4538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records after cleaning: 47653\n",
      "Countries represented: ['GB', 'IE']\n",
      "Cleaned data saved to gbif_barn_owl_GB-IE_2010-2025.csv\n",
      "\n",
      "Dataset summary:\n",
      "Countries: 2\n",
      "Records per country:\n",
      "countryCode\n",
      "GB    46482\n",
      "IE     1171\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 5. Load occurrences into pandas\n",
    "occ_file = os.path.join(extract_dir, f\"{download_key}.csv\")\n",
    "df = pd.read_csv(occ_file, sep=\"\\t\", low_memory=False)\n",
    "\n",
    "# 6. Drop any records missing coordinates\n",
    "df_clean = df.dropna(subset=[\"decimalLatitude\", \"decimalLongitude\"])\n",
    "\n",
    "# # 7. Clean and convert eventDate column\n",
    "# # First, drop records with missing eventDate\n",
    "# df_clean = df_clean.dropna(subset=[\"eventDate\"])\n",
    "\n",
    "# # Convert eventDate to datetime format (handles various date formats)\n",
    "# df_clean[\"eventDate\"] = pd.to_datetime(df_clean[\"eventDate\"], errors=\"coerce\")\n",
    "\n",
    "# # Drop any records where eventDate conversion failed\n",
    "# df_clean = df_clean.dropna(subset=[\"eventDate\"])\n",
    "\n",
    "print(f\"Total records after cleaning: {len(df_clean)}\")\n",
    "print(f\"Countries represented: {sorted(df_clean['countryCode'].unique())}\")\n",
    "\n",
    "# 8. Save cleaned CSV ready for ArcGIS import\n",
    "start_year = DATE_START.split('-')[0]\n",
    "end_year = DATE_END.split('-')[0]\n",
    "output_csv = f\"gbif_barn_owl_GB-IE_{start_year}-{end_year}.csv\"\n",
    "df_clean.to_csv(output_csv, index=False)\n",
    "print(f\"Cleaned data saved to {output_csv}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(f\"\\nDataset summary:\")\n",
    "# print(f\"Date range: {df_clean['eventDate'].min().strftime('%Y-%m-%d')} to {df_clean['eventDate'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Countries: {len(df_clean['countryCode'].unique())}\")\n",
    "print(f\"Records per country:\")\n",
    "print(df_clean['countryCode'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf28b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up temporary files...\n",
      "Removed ZIP file: 0012178-250802193616735.zip\n",
      "Removed directory: 0012178-250802193616735\n",
      "Cleanup completed!\n",
      "Final output file: gbif_barn_owl_GB-IE_2010-2025.csv\n"
     ]
    }
   ],
   "source": [
    "# 9. Cleanup temporary files\n",
    "import shutil\n",
    "\n",
    "print(\"Cleaning up temporary files...\")\n",
    "\n",
    "# Remove the ZIP file\n",
    "if os.path.exists(zip_path):\n",
    "    os.remove(zip_path)\n",
    "    print(f\"Removed ZIP file: {zip_path}\")\n",
    "else:\n",
    "    print(f\"ZIP file not found: {zip_path}\")\n",
    "\n",
    "# Remove the extracted directory and all its contents\n",
    "if os.path.exists(extract_dir):\n",
    "    shutil.rmtree(extract_dir)\n",
    "    print(f\"Removed directory: {extract_dir}\")\n",
    "else:\n",
    "    print(f\"Directory not found: {extract_dir}\")\n",
    "\n",
    "print(\"Cleanup completed!\")\n",
    "print(f\"Final output file: {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
